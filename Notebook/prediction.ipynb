{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Demo\n",
    "\n",
    "This notebook demonstrates how to use a trained artificial neural network (ANN) model to predict customer churn using new customer data. The notebook loads the pre-trained model and preprocessors, prepares input data, and makes predictions.\n",
    "\n",
    "## What this notebook covers:\n",
    "- Loading the trained model and preprocessors\n",
    "- Preparing input data for prediction\n",
    "- Encoding categorical variables\n",
    "- Scaling features\n",
    "- Making predictions and interpreting results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, we'll import all the necessary libraries for loading the model and making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "TensorFlow version: 2.15.0\n",
      "Pandas version: 2.3.1\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for model loading and prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model and Preprocessors\n",
    "\n",
    "Now we'll load the pre-trained ANN model and all the preprocessors (encoders and scaler) that were saved during training. These files should be in the `PickelFiles/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully from model.keras\n",
      "‚úì Geography encoder loaded successfully\n",
      "‚úì Gender encoder loaded successfully\n",
      "‚úì Scaler loaded successfully\n",
      "\n",
      "üéâ All model components loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the PickelFiles directory\n",
    "PICKLE_DIR = \"../PickelFiles/\"\n",
    "\n",
    "# Try to load the trained model (prefer .keras format, fallback to .h5)\n",
    "try:\n",
    "    model_path = os.path.join(PICKLE_DIR, \"model.keras\")\n",
    "    if os.path.exists(model_path):\n",
    "        model = load_model(model_path)\n",
    "        print(\"‚úì Model loaded successfully from model.keras\")\n",
    "    else:\n",
    "        model_path = os.path.join(PICKLE_DIR, \"model.h5\")\n",
    "        model = load_model(model_path)\n",
    "        print(\"‚úì Model loaded successfully from model.h5\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load the one-hot encoder for Geography\n",
    "geo_encoder_path = os.path.join(PICKLE_DIR, 'onehot_encoder_geo.pkl')\n",
    "if os.path.exists(geo_encoder_path):\n",
    "    try:\n",
    "        with open(geo_encoder_path, 'rb') as file:\n",
    "            label_encoder_geo = pickle.load(file)\n",
    "        print(\"‚úì Geography encoder loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading geography encoder: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"‚ùå Geography encoder file not found at: {geo_encoder_path}\")\n",
    "    print(\"   Please ensure the encoder was saved during training and the path is correct.\")\n",
    "    label_encoder_geo = None  # Set to None to avoid breaking the notebook\n",
    "\n",
    "# Load the label encoder for Gender\n",
    "try:\n",
    "    with open(os.path.join(PICKLE_DIR, 'label_encoder_gender.pkl'), 'rb') as file:\n",
    "        label_encoder_gender = pickle.load(file)\n",
    "    print(\"‚úì Gender encoder loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading gender encoder: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load the feature scaler\n",
    "try:\n",
    "    with open(os.path.join(PICKLE_DIR, 'scaler.pkl'), 'rb') as file:\n",
    "        scaler = pickle.load(file)\n",
    "    print(\"‚úì Scaler loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading scaler: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nüéâ All model components loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Input Data for Prediction\n",
    "\n",
    "Let's create sample customer data to demonstrate how predictions work. In a real-world scenario, this data would come from your customer database or user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sample customer data:\n",
      "  CreditScore: 600\n",
      "  Geography: France\n",
      "  Gender: Male\n",
      "  Age: 40\n",
      "  Tenure: 3\n",
      "  Balance: 60000\n",
      "  NumOfProducts: 2\n",
      "  HasCrCard: 1\n",
      "  IsActiveMember: 1\n",
      "  EstimatedSalary: 50000\n",
      "\n",
      "üìã Input DataFrame shape: (1, 10)\n",
      "\n",
      "    CreditScore Geography Gender  Age  Tenure  Balance  NumOfProducts  \\\n",
      "0          600    France   Male   40       3    60000              2   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0          1               1            50000  \n"
     ]
    }
   ],
   "source": [
    "# Sample customer data for prediction\n",
    "# In practice, this would come from user input or database query\n",
    "input_data = {\n",
    "    'CreditScore': 600,        # Customer's credit score (300-850)\n",
    "    'Geography': 'France',     # Customer's country (France, Germany, Spain)\n",
    "    'Gender': 'Male',          # Customer's gender (Male, Female)\n",
    "    'Age': 40,                 # Customer's age in years\n",
    "    'Tenure': 3,               # Number of years as bank customer\n",
    "    'Balance': 60000,          # Account balance in currency units\n",
    "    'NumOfProducts': 2,        # Number of bank products used (1-4)\n",
    "    'HasCrCard': 1,           # Has credit card (1=Yes, 0=No)\n",
    "    'IsActiveMember': 1,       # Is active member (1=Yes, 0=No)\n",
    "    'EstimatedSalary': 50000   # Estimated annual salary\n",
    "}\n",
    "\n",
    "print(\"üìä Sample customer data:\")\n",
    "for key, value in input_data.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "    \n",
    "# Convert to DataFrame for easier manipulation\n",
    "input_df = pd.DataFrame([input_data])\n",
    "print(f\"\\nüìã Input DataFrame shape: {input_df.shape}\")\n",
    "print(\"\\n\", input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "We need to apply the same preprocessing steps that were used during training:\n",
    "1. **Encode Gender**: Convert categorical gender to numerical using Label Encoder\n",
    "2. **One-hot encode Geography**: Convert country names to binary columns\n",
    "3. **Scale Features**: Normalize all features using the same scaler from training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 One-Hot Encode Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Geography one-hot encoding successful:\n",
      "  Original: France\n",
      "  Encoded shape: (1, 3)\n",
      "\n",
      "üìä One-hot encoded geography:\n",
      "   Geography_France  Geography_Germany  Geography_Spain\n",
      "0               1.0                0.0              0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'Geography' column using the trained encoder\n",
    "try:\n",
    "    # Transform the geography value to one-hot encoded format\n",
    "    geo_encoded = label_encoder_geo.transform([[input_data['Geography']]]).toarray()\n",
    "    \n",
    "    # Create DataFrame with proper column names\n",
    "    geo_encoded_df = pd.DataFrame(\n",
    "        geo_encoded, \n",
    "        columns=label_encoder_geo.get_feature_names_out(['Geography'])\n",
    "    )\n",
    "    \n",
    "    print(\"üåç Geography one-hot encoding successful:\")\n",
    "    print(f\"  Original: {input_data['Geography']}\")\n",
    "    print(f\"  Encoded shape: {geo_encoded_df.shape}\")\n",
    "    print(\"\\nüìä One-hot encoded geography:\")\n",
    "    print(geo_encoded_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error encoding geography: {e}\")\n",
    "    print(f\"   Make sure '{input_data['Geography']}' was in the training data\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Label Encode Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Gender label encoding successful:\n",
      "  Original: Male\n",
      "  Encoded: 1\n",
      "\n",
      "üìä DataFrame after gender encoding:\n",
      "   CreditScore Geography  Gender  Age  Tenure  Balance  NumOfProducts  \\\n",
      "0          600    France       1   40       3    60000              2   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0          1               1            50000  \n"
     ]
    }
   ],
   "source": [
    "# Label encode the 'Gender' column using the trained encoder\n",
    "try:\n",
    "    # Store original gender for reference\n",
    "    original_gender = input_df['Gender'].iloc[0]\n",
    "    \n",
    "    # Transform gender to numerical format\n",
    "    input_df['Gender'] = label_encoder_gender.transform(input_df['Gender'])\n",
    "    \n",
    "    print(\"üë§ Gender label encoding successful:\")\n",
    "    print(f\"  Original: {original_gender}\")\n",
    "    print(f\"  Encoded: {input_df['Gender'].iloc[0]}\")\n",
    "    print(\"\\nüìä DataFrame after gender encoding:\")\n",
    "    print(input_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error encoding gender: {e}\")\n",
    "    print(f\"   Make sure '{original_gender}' was in the training data\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Features combined successfully:\n",
      "  Original features: 10 columns\n",
      "  Geography encoded: 3 columns\n",
      "  Final features: 12 columns\n",
      "\n",
      "üìä Final feature DataFrame:\n",
      "   CreditScore  Gender  Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
      "0          600       1   40       3    60000              2          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "0               1            50000               1.0                0.0   \n",
      "\n",
      "   Geography_Spain  \n",
      "0              0.0  \n",
      "\n",
      "üìã Column names: ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n"
     ]
    }
   ],
   "source": [
    "# Combine the original features (without Geography) with the one-hot encoded geography columns\n",
    "# This creates the final feature set that matches the training data format\n",
    "try:\n",
    "    # Remove the original 'Geography' column and concatenate with one-hot encoded columns\n",
    "    input_df_final = pd.concat([\n",
    "        input_df.drop(\"Geography\", axis=1),  # All features except Geography\n",
    "        geo_encoded_df                       # One-hot encoded Geography columns\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(\"üîó Features combined successfully:\")\n",
    "    print(f\"  Original features: {input_df.shape[1]} columns\")\n",
    "    print(f\"  Geography encoded: {geo_encoded_df.shape[1]} columns\")\n",
    "    print(f\"  Final features: {input_df_final.shape[1]} columns\")\n",
    "    print(\"\\nüìä Final feature DataFrame:\")\n",
    "    print(input_df_final)\n",
    "    print(f\"\\nüìã Column names: {list(input_df_final.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error combining features: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Feature scaling successful:\n",
      "  Original shape: (1, 12)\n",
      "  Scaled shape: (1, 12)\n",
      "  Data type: float64\n",
      "\n",
      "üìä Scaled features (first 5 values): [-0.52544045  0.90750738  0.10007155 -0.6962018  -0.2629485 ]\n",
      "üìä Feature range: [-0.867, 1.002]\n"
     ]
    }
   ],
   "source": [
    "# Scale the input features using the same scaler that was used during training\n",
    "# This ensures the features are in the same range as the training data\n",
    "try:\n",
    "    # Apply the same scaling transformation used during training\n",
    "    input_scaled = scaler.transform(input_df_final)\n",
    "    \n",
    "    print(\"üìè Feature scaling successful:\")\n",
    "    print(f\"  Original shape: {input_df_final.shape}\")\n",
    "    print(f\"  Scaled shape: {input_scaled.shape}\")\n",
    "    print(f\"  Data type: {input_scaled.dtype}\")\n",
    "    print(f\"\\nüìä Scaled features (first 5 values): {input_scaled[0][:5]}\")\n",
    "    print(f\"üìä Feature range: [{input_scaled.min():.3f}, {input_scaled.max():.3f}]\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error scaling features: {e}\")\n",
    "    print(\"   Make sure the number of features matches the training data\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Prediction\n",
    "\n",
    "Now we'll use our trained ANN model to predict whether this customer is likely to churn. The model outputs a probability between 0 and 1, where values closer to 1 indicate higher churn likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Prediction completed successfully:\n",
      "  Raw prediction output: [[0.0344639]]\n",
      "  Churn probability: 0.0345 (3.45%)\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict churn probability\n",
    "try:\n",
    "    # Make prediction using the scaled input data\n",
    "    prediction = model.predict(input_scaled, verbose=0)\n",
    "    \n",
    "    # Extract the probability value (model outputs a 2D array)\n",
    "    prediction_proba = prediction[0][0]\n",
    "    \n",
    "    print(\"üîÆ Prediction completed successfully:\")\n",
    "    print(f\"  Raw prediction output: {prediction}\")\n",
    "    print(f\"  Churn probability: {prediction_proba:.4f} ({prediction_proba*100:.2f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error making prediction: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpret Results\n",
    "\n",
    "Let's interpret the prediction results and provide actionable insights based on the churn probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ CHURN PREDICTION ANALYSIS\n",
      "============================================================\n",
      "‚úÖ Churn Probability: 0.0345 (3.45%)\n",
      "‚úÖ Risk Level: LOW RISK\n",
      "‚úÖ Recommendation: CUSTOMER LIKELY TO STAY\n",
      "\n",
      "============================================================\n",
      "üìä CUSTOMER PROFILE ANALYSIS\n",
      "============================================================\n",
      "üë§ Customer Demographics:\n",
      "   Age: 40 years\n",
      "   Gender: Male\n",
      "   Geography: France\n",
      "\n",
      "üí≥ Banking Relationship:\n",
      "   Credit Score: 600\n",
      "   Tenure: 3 years\n",
      "   Products Used: 2\n",
      "   Has Credit Card: Yes\n",
      "   Active Member: Yes\n",
      "\n",
      "üí∞ Financial Profile:\n",
      "   Account Balance: $60,000\n",
      "   Estimated Salary: $50,000\n",
      "\n",
      "üîç RISK FACTORS ANALYSIS:\n",
      "   ‚úÖ No major risk factors identified\n"
     ]
    }
   ],
   "source": [
    "# Interpret the prediction results with detailed analysis\n",
    "def interpret_churn_prediction(probability, customer_data):\n",
    "    \"\"\"\n",
    "    Provide detailed interpretation of churn prediction\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üéØ CHURN PREDICTION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic prediction\n",
    "    if probability > 0.5:\n",
    "        risk_level = \"HIGH RISK\"\n",
    "        emoji = \"üö®\"\n",
    "        recommendation = \"IMMEDIATE ATTENTION REQUIRED\"\n",
    "    elif probability > 0.3:\n",
    "        risk_level = \"MEDIUM RISK\"\n",
    "        emoji = \"‚ö†Ô∏è\"\n",
    "        recommendation = \"MONITOR CLOSELY\"\n",
    "    else:\n",
    "        risk_level = \"LOW RISK\"\n",
    "        emoji = \"‚úÖ\"\n",
    "        recommendation = \"CUSTOMER LIKELY TO STAY\"\n",
    "    \n",
    "    print(f\"{emoji} Churn Probability: {probability:.4f} ({probability*100:.2f}%)\")\n",
    "    print(f\"{emoji} Risk Level: {risk_level}\")\n",
    "    print(f\"{emoji} Recommendation: {recommendation}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä CUSTOMER PROFILE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyze customer characteristics\n",
    "    print(f\"üë§ Customer Demographics:\")\n",
    "    print(f\"   Age: {customer_data['Age']} years\")\n",
    "    print(f\"   Gender: {customer_data['Gender']}\")\n",
    "    print(f\"   Geography: {customer_data['Geography']}\")\n",
    "    \n",
    "    print(f\"\\nüí≥ Banking Relationship:\")\n",
    "    print(f\"   Credit Score: {customer_data['CreditScore']}\")\n",
    "    print(f\"   Tenure: {customer_data['Tenure']} years\")\n",
    "    print(f\"   Products Used: {customer_data['NumOfProducts']}\")\n",
    "    print(f\"   Has Credit Card: {'Yes' if customer_data['HasCrCard'] else 'No'}\")\n",
    "    print(f\"   Active Member: {'Yes' if customer_data['IsActiveMember'] else 'No'}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ Financial Profile:\")\n",
    "    print(f\"   Account Balance: ${customer_data['Balance']:,}\")\n",
    "    print(f\"   Estimated Salary: ${customer_data['EstimatedSalary']:,}\")\n",
    "    \n",
    "    # Risk factors analysis\n",
    "    print(f\"\\nüîç RISK FACTORS ANALYSIS:\")\n",
    "    risk_factors = []\n",
    "    \n",
    "    if customer_data['Age'] > 45:\n",
    "        risk_factors.append(\"Age above 45 (higher churn risk)\")\n",
    "    if customer_data['NumOfProducts'] == 1:\n",
    "        risk_factors.append(\"Only using 1 product (low engagement)\")\n",
    "    if customer_data['IsActiveMember'] == 0:\n",
    "        risk_factors.append(\"Inactive member (disengaged)\")\n",
    "    if customer_data['Balance'] == 0:\n",
    "        risk_factors.append(\"Zero balance (inactive account)\")\n",
    "    if customer_data['Tenure'] <= 2:\n",
    "        risk_factors.append(\"Short tenure (new customer)\")\n",
    "    \n",
    "    if risk_factors:\n",
    "        for factor in risk_factors:\n",
    "            print(f\"   ‚ö†Ô∏è {factor}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No major risk factors identified\")\n",
    "    \n",
    "    return risk_level, recommendation\n",
    "\n",
    "# Run the analysis\n",
    "risk_level, recommendation = interpret_churn_prediction(prediction_proba, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Actionable Recommendations\n",
    "\n",
    "Based on the churn prediction, here are specific actions that can be taken to reduce churn risk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üí° ACTIONABLE RECOMMENDATIONS\n",
      "============================================================\n",
      "Based on LOW RISK classification:\n",
      "1. ‚úÖ Continue standard engagement programs\n",
      "2. üéâ Consider them for referral programs\n",
      "3. üìà Monitor for upselling opportunities\n",
      "4. üí¨ Collect feedback to maintain satisfaction\n",
      "\n",
      "üìÖ Recommended Timeline:\n",
      "   ‚è∞ Include in next quarterly review\n"
     ]
    }
   ],
   "source": [
    "# Generate specific actionable recommendations based on the prediction\n",
    "def generate_recommendations(probability, customer_data, risk_level):\n",
    "    \"\"\"\n",
    "    Generate specific recommendations for customer retention\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üí° ACTIONABLE RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    if probability > 0.5:\n",
    "        # High risk customers\n",
    "        recommendations.extend([\n",
    "            \"üî• URGENT: Schedule immediate customer outreach call\",\n",
    "            \"üí∞ Offer loyalty rewards or account upgrades\",\n",
    "            \"üìû Assign dedicated relationship manager\",\n",
    "            \"üéÅ Provide exclusive offers or fee waivers\"\n",
    "        ])\n",
    "    elif probability > 0.3:\n",
    "        # Medium risk customers\n",
    "        recommendations.extend([\n",
    "            \"üìß Send targeted retention email campaign\",\n",
    "            \"üìä Analyze usage patterns for personalized offers\",\n",
    "            \"üéØ Include in upcoming promotional campaigns\",\n",
    "            \"üí≥ Suggest additional products that add value\"\n",
    "        ])\n",
    "    else:\n",
    "        # Low risk customers\n",
    "        recommendations.extend([\n",
    "            \"‚úÖ Continue standard engagement programs\",\n",
    "            \"üéâ Consider them for referral programs\",\n",
    "            \"üìà Monitor for upselling opportunities\",\n",
    "            \"üí¨ Collect feedback to maintain satisfaction\"\n",
    "        ])\n",
    "    \n",
    "    # Specific recommendations based on customer profile\n",
    "    if customer_data['NumOfProducts'] == 1:\n",
    "        recommendations.append(\"üîÑ Recommend additional banking products\")\n",
    "    \n",
    "    if customer_data['IsActiveMember'] == 0:\n",
    "        recommendations.append(\"üöÄ Launch re-engagement campaign\")\n",
    "    \n",
    "    if customer_data['Balance'] == 0:\n",
    "        recommendations.append(\"üí≥ Encourage account usage with incentives\")\n",
    "    \n",
    "    if customer_data['Age'] > 45:\n",
    "        recommendations.append(\"üë¥ Focus on retirement planning services\")\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(f\"Based on {risk_level} classification:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    \n",
    "    print(f\"\\nüìÖ Recommended Timeline:\")\n",
    "    if probability > 0.5:\n",
    "        print(\"   ‚è∞ Take action within 24-48 hours\")\n",
    "    elif probability > 0.3:\n",
    "        print(\"   ‚è∞ Take action within 1-2 weeks\")\n",
    "    else:\n",
    "        print(\"   ‚è∞ Include in next quarterly review\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations for this customer\n",
    "recommendations = generate_recommendations(prediction_proba, input_data, risk_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use a trained ANN model for customer churn prediction. The complete workflow includes:\n",
    "\n",
    "### ‚úÖ What We Accomplished:\n",
    "1. **Model Loading**: Successfully loaded pre-trained model and preprocessors\n",
    "2. **Data Preprocessing**: Applied the same transformations used during training\n",
    "3. **Prediction**: Generated churn probability for new customer data\n",
    "4. **Analysis**: Provided detailed risk assessment and customer profiling\n",
    "5. **Recommendations**: Generated actionable retention strategies\n",
    "\n",
    "### üîÑ Next Steps for Production Use:\n",
    "1. **Integration**: Integrate this prediction pipeline into your CRM system\n",
    "2. **Automation**: Automate predictions for batch customer scoring\n",
    "3. **Monitoring**: Track prediction accuracy and model performance over time\n",
    "4. **Feedback Loop**: Collect outcomes to retrain and improve the model\n",
    "5. **A/B Testing**: Test retention strategies based on predictions\n",
    "\n",
    "### üìä Key Metrics to Track:\n",
    "- Prediction accuracy vs. actual churn\n",
    "- Customer retention rate improvements\n",
    "- ROI of retention campaigns\n",
    "- Model drift and performance degradation\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Remember**: This model is a tool to support decision-making, not replace human judgment. Always consider business context and customer relationships when taking action based on predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

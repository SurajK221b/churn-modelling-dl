{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Model - Experiments\n",
    "\n",
    "This notebook contains the complete workflow for building a deep learning model to predict customer churn using an Artificial Neural Network (ANN). \n",
    "\n",
    "## Project Overview\n",
    "- **Objective**: Predict whether a bank customer will churn (leave the bank)\n",
    "- **Model**: Deep Neural Network with TensorFlow/Keras\n",
    "- **Features**: Customer demographics, account information, and banking behavior\n",
    "- **Target**: Binary classification (Churn: 1, Stay: 0)\n",
    "\n",
    "## Workflow\n",
    "1. Data Loading and Exploration\n",
    "2. Data Preprocessing and Feature Engineering\n",
    "3. Model Architecture Design\n",
    "4. Model Training with Callbacks\n",
    "5. Model Evaluation and Saving\n",
    "\n",
    "## File Structure\n",
    "- **Input**: `../Data/Churn_Modelling.csv`\n",
    "- **Output**: Model and preprocessors saved to `../PickelFiles/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìä Pandas version: 2.3.1\n",
      "üî¢ NumPy version: 1.26.4\n",
      "üöÄ Ready for data analysis and model training!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT NECESSARY LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Model persistence\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
    "print(\"üöÄ Ready for data analysis and model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üìä Dataset shape: (10000, 14)\n",
      "üìã Columns: ['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n",
      "\n",
      "üìÑ First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. DATA LOADING AND INITIAL EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load the customer churn dataset from the correct path\n",
    "try:\n",
    "    data = pd.read_csv(\"../Data/Churn_Modelling.csv\")\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìä Dataset shape: {data.shape}\")\n",
    "    print(f\"üìã Columns: {list(data.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Dataset not found at '../Data/Churn_Modelling.csv'\")\n",
    "    print(\"üí° Please ensure the file exists in the Data directory\")\n",
    "    raise\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìÑ First 5 rows of the dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Information:\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "üìà Basic Statistics:\n",
      "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n",
      "\n",
      "üéØ Target Variable Distribution:\n",
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "Churn Rate: 20.37%\n",
      "\n",
      "‚úÖ Dropped columns: ['RowNumber', 'CustomerId', 'Surname']\n",
      "üìã Remaining columns: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n",
      "üìä New dataset shape: (10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. DATA PREPROCESSING AND CLEANING\n",
    "# =============================================================================\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(\"=\" * 50)\n",
    "data.info()\n",
    "\n",
    "print(\"\\nüìà Basic Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "print(\"\\nüéØ Target Variable Distribution:\")\n",
    "print(data['Exited'].value_counts())\n",
    "print(f\"Churn Rate: {data['Exited'].mean():.2%}\")\n",
    "\n",
    "# Drop irrelevant columns that don't contribute to prediction\n",
    "# - RowNumber: Just an index, not a feature\n",
    "# - CustomerId: Unique identifier, not predictive\n",
    "# - Surname: Customer name, not relevant for churn prediction\n",
    "columns_to_drop = ['RowNumber', 'CustomerId', 'Surname']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(f\"\\n‚úÖ Dropped columns: {columns_to_drop}\")\n",
    "print(f\"üìã Remaining columns: {list(data.columns)}\")\n",
    "print(f\"üìä New dataset shape: {data.shape}\")\n",
    "\n",
    "# Display cleaned dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Encoding Gender column...\n",
      "Original Gender values: ['Female' 'Male']\n",
      "‚úÖ Gender encoding completed:\n",
      "üìã Original gender classes: ['Female' 'Male']\n",
      "üî¢ Encoded values: {'Female': 0, 'Male': 1}\n",
      "üìä Unique values in Gender column: [0, 1]\n",
      "\n",
      "üìÑ Sample data after Gender encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "5          645     Spain       1   44       8  113755.78              2   \n",
       "6          822    France       1   50       7       0.00              2   \n",
       "7          376   Germany       0   29       4  115046.74              4   \n",
       "8          501    France       1   44       4  142051.07              2   \n",
       "9          684    France       1   27       2  134603.88              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  \n",
       "5          1               0        149756.71       1  \n",
       "6          1               1         10062.80       0  \n",
       "7          1               0        119346.88       1  \n",
       "8          0               1         74940.50       0  \n",
       "9          1               1         71725.73       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. CATEGORICAL VARIABLE ENCODING - GENDER\n",
    "# =============================================================================\n",
    "\n",
    "# 4.1 Label Encoding for Gender (Binary categorical variable)\n",
    "# Gender has only 2 categories (Male/Female), so LabelEncoder is appropriate\n",
    "print(\"üî§ Encoding Gender column...\")\n",
    "print(f\"Original Gender values: {data['Gender'].unique()}\")\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "print(\"‚úÖ Gender encoding completed:\")\n",
    "print(f\"üìã Original gender classes: {label_encoder_gender.classes_}\")\n",
    "print(f\"üî¢ Encoded values: {dict(zip(label_encoder_gender.classes_, range(len(label_encoder_gender.classes_))))}\")\n",
    "print(f\"üìä Unique values in Gender column: {sorted(data['Gender'].unique())}\")\n",
    "\n",
    "# Display sample of data with encoded Gender column\n",
    "print(\"\\nüìÑ Sample data after Gender encoding:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Geography Analysis:\n",
      "Unique Geography values: ['France' 'Spain' 'Germany']\n",
      "Number of unique geography values: 3\n",
      "Geography distribution:\n",
      "Geography\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîÑ Applying One-Hot Encoding to Geography...\n",
      "‚úÖ Geography One-Hot Encoding completed:\n",
      "üìä Original geography categories: ['France' 'Spain' 'Germany']\n",
      "üìè Encoded array shape: (10000, 3)\n",
      "üè∑Ô∏è Feature names: ['Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
      "üìä First 5 rows of encoded geography:\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. CATEGORICAL VARIABLE ENCODING - GEOGRAPHY\n",
    "# =============================================================================\n",
    "\n",
    "# 5.1 Check unique values in Geography column before encoding\n",
    "print(\"üåç Geography Analysis:\")\n",
    "geography_values = data['Geography'].unique()\n",
    "print(f\"Unique Geography values: {geography_values}\")\n",
    "print(f\"Number of unique geography values: {len(geography_values)}\")\n",
    "print(f\"Geography distribution:\\n{data['Geography'].value_counts()}\")\n",
    "\n",
    "# 5.2 One-Hot Encoding for Geography (Multi-categorical variable)\n",
    "# Geography has 3+ categories, so One-Hot Encoding prevents ordinality issues\n",
    "# This creates binary columns for each geography category\n",
    "print(\"\\nüîÑ Applying One-Hot Encoding to Geography...\")\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder()\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']])\n",
    "\n",
    "print(\"‚úÖ Geography One-Hot Encoding completed:\")\n",
    "print(f\"üìä Original geography categories: {data['Geography'].unique()}\")\n",
    "print(f\"üìè Encoded array shape: {geo_encoded.shape}\")\n",
    "print(f\"üè∑Ô∏è Feature names: {list(onehot_encoder_geo.get_feature_names_out(['Geography']))}\")\n",
    "\n",
    "# Convert sparse matrix to dense array for easier handling\n",
    "geo_encoded_array = geo_encoded.toarray()\n",
    "print(f\"üìä First 5 rows of encoded geography:\")\n",
    "print(geo_encoded_array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Generated feature names from One-Hot Encoding:\n",
      "1. Geography_France\n",
      "2. Geography_Germany\n",
      "3. Geography_Spain\n",
      "\n",
      "üìä Total new features created: 3\n",
      "üí° Each geography location gets its own binary column\n"
     ]
    }
   ],
   "source": [
    "# Display the feature names created by One-Hot Encoder\n",
    "print(\"üè∑Ô∏è Generated feature names from One-Hot Encoding:\")\n",
    "feature_names = onehot_encoder_geo.get_feature_names_out(['Geography'])\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"{i+1}. {name}\")\n",
    "\n",
    "print(f\"\\nüìä Total new features created: {len(feature_names)}\")\n",
    "print(\"üí° Each geography location gets its own binary column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting encoded geography to DataFrame...\n",
      "‚úÖ Geography encoding DataFrame created\n",
      "üìä Shape: (10000, 3)\n",
      "üìã Columns: ['Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
      "\n",
      "üìÑ Encoded Geography DataFrame (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography_France  Geography_Germany  Geography_Spain\n",
       "0               1.0                0.0              0.0\n",
       "1               0.0                0.0              1.0\n",
       "2               1.0                0.0              0.0\n",
       "3               1.0                0.0              0.0\n",
       "4               0.0                0.0              1.0\n",
       "5               0.0                0.0              1.0\n",
       "6               1.0                0.0              0.0\n",
       "7               0.0                1.0              0.0\n",
       "8               1.0                0.0              0.0\n",
       "9               1.0                0.0              0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the encoded array to a DataFrame for easier handling\n",
    "print(\"üîÑ Converting encoded geography to DataFrame...\")\n",
    "\n",
    "geo_encoded_df = pd.DataFrame(\n",
    "    geo_encoded_array, \n",
    "    columns=onehot_encoder_geo.get_feature_names_out(['Geography']),\n",
    "    index=data.index  # Maintain the same index as original data\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Geography encoding DataFrame created\")\n",
    "print(f\"üìä Shape: {geo_encoded_df.shape}\")\n",
    "print(f\"üìã Columns: {list(geo_encoded_df.columns)}\")\n",
    "\n",
    "print(\"\\nüìÑ Encoded Geography DataFrame (first 10 rows):\")\n",
    "geo_encoded_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Combining original data with encoded geography features...\n",
      "üìä Original data shape: (10000, 11)\n",
      "üìä After dropping Geography: (10000, 10)\n",
      "‚úÖ Feature engineering completed!\n",
      "üìä Final dataset shape: (10000, 13)\n",
      "üìã Final columns: ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
      "‚ûï Added 3 new encoded columns\n",
      "\n",
      "üîç Missing values check: 0 missing values\n",
      "\n",
      "üìÑ Final Preprocessed Dataset (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. FEATURE ENGINEERING - COMBINE ENCODED FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîÑ Combining original data with encoded geography features...\")\n",
    "\n",
    "# Store original shape for comparison\n",
    "original_shape = data.shape\n",
    "print(f\"üìä Original data shape: {original_shape}\")\n",
    "\n",
    "# Remove the original categorical Geography column\n",
    "data = data.drop('Geography', axis=1)\n",
    "print(f\"üìä After dropping Geography: {data.shape}\")\n",
    "\n",
    "# Concatenate the encoded geography features with the main dataset\n",
    "data = pd.concat([data, geo_encoded_df], axis=1)\n",
    "\n",
    "print(\"‚úÖ Feature engineering completed!\")\n",
    "print(f\"üìä Final dataset shape: {data.shape}\")\n",
    "print(f\"üìã Final columns: {list(data.columns)}\")\n",
    "print(f\"‚ûï Added {data.shape[1] - (original_shape[1] - 1)} new encoded columns\")\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"\\nüîç Missing values check: {data.isnull().sum().sum()} missing values\")\n",
    "\n",
    "# Display the final preprocessed dataset\n",
    "print(\"\\nüìÑ Final Preprocessed Dataset (first 5 rows):\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Created/verified PickelFiles directory\n",
      "üíæ Saving preprocessors...\n",
      "‚úÖ Gender Label Encoder saved to '../PickelFiles/label_encoder_gender.pkl'\n",
      "‚úÖ Geography One-Hot Encoder saved to '../PickelFiles/onehot_encoder_geo.pkl'\n",
      "\n",
      "üíæ All preprocessors saved successfully!\n",
      "üîó These files will be used by the Streamlit app for consistent preprocessing\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. SAVE PREPROCESSORS FOR FUTURE USE\n",
    "# =============================================================================\n",
    "\n",
    "# Create PickelFiles directory if it doesn't exist\n",
    "os.makedirs('../PickelFiles', exist_ok=True)\n",
    "print(\"üìÅ Created/verified PickelFiles directory\")\n",
    "\n",
    "# Save the fitted encoders and scaler for use in prediction\n",
    "# These will be needed to preprocess new data for predictions\n",
    "print(\"üíæ Saving preprocessors...\")\n",
    "\n",
    "try:\n",
    "    # Save Label Encoder for Gender\n",
    "    with open('../PickelFiles/label_encoder_gender.pkl', 'wb') as file:\n",
    "        pickle.dump(label_encoder_gender, file)\n",
    "    print(\"‚úÖ Gender Label Encoder saved to '../PickelFiles/label_encoder_gender.pkl'\")\n",
    "\n",
    "    # Save One-Hot Encoder for Geography\n",
    "    with open('../PickelFiles/onehot_encoder_geo.pkl', 'wb') as file:\n",
    "        pickle.dump(onehot_encoder_geo, file)\n",
    "    print(\"‚úÖ Geography One-Hot Encoder saved to '../PickelFiles/onehot_encoder_geo.pkl'\")\n",
    "\n",
    "    print(\"\\nüíæ All preprocessors saved successfully!\")\n",
    "    print(\"üîó These files will be used by the Streamlit app for consistent preprocessing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving preprocessors: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Final Data Verification:\n",
      "üìä Shape: (10000, 13)\n",
      "üìã Columns: ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
      "üéØ Target column present: True\n",
      "\n",
      "üìà Data Types:\n",
      "CreditScore            int64\n",
      "Gender                 int32\n",
      "Age                    int64\n",
      "Tenure                 int64\n",
      "Balance              float64\n",
      "NumOfProducts          int64\n",
      "HasCrCard              int64\n",
      "IsActiveMember         int64\n",
      "EstimatedSalary      float64\n",
      "Exited                 int64\n",
      "Geography_France     float64\n",
      "Geography_Germany    float64\n",
      "Geography_Spain      float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the final processed data structure\n",
    "print(\"üîç Final Data Verification:\")\n",
    "print(f\"üìä Shape: {data.shape}\")\n",
    "print(f\"üìã Columns: {list(data.columns)}\")\n",
    "print(f\"üéØ Target column present: {'Exited' in data.columns}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nüìà Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Display final dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Feature-Target Separation:\n",
      "üìä Features (X) shape: (10000, 12)\n",
      "üéØ Target (y) shape: (10000,)\n",
      "üìã Feature columns: ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
      "üéØ Target distribution: {0: 7963, 1: 2037}\n",
      "\n",
      "üìä Train-Test Split:\n",
      "üìà Training set: X_train (8000, 12), y_train (8000,)\n",
      "üìâ Testing set: X_test (2000, 12), y_test (2000,)\n",
      "üéØ Train churn rate: 20.38%\n",
      "üéØ Test churn rate: 20.35%\n",
      "\n",
      "‚öñÔ∏è Feature Scaling:\n",
      "‚úÖ Features scaled using StandardScaler\n",
      "üìä Scaled training data shape: (8000, 12)\n",
      "üìä Scaled testing data shape: (2000, 12)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. PREPARE FEATURES AND TARGET VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "# Features: All columns except 'Exited' (the target we want to predict)\n",
    "# Target: 'Exited' column (1 = customer churned, 0 = customer stayed)\n",
    "\n",
    "X = data.drop('Exited', axis=1)  # Features\n",
    "y = data['Exited']               # Target\n",
    "\n",
    "print(\"üéØ Feature-Target Separation:\")\n",
    "print(f\"üìä Features (X) shape: {X.shape}\")\n",
    "print(f\"üéØ Target (y) shape: {y.shape}\")\n",
    "print(f\"üìã Feature columns: {list(X.columns)}\")\n",
    "print(f\"üéØ Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. TRAIN-TEST SPLIT AND FEATURE SCALING\n",
    "# =============================================================================\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# 80% for training, 20% for testing\n",
    "# random_state=42 ensures reproducible results\n",
    "# stratify=y maintains the same proportion of target classes in both sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Train-Test Split:\")\n",
    "print(f\"üìà Training set: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"üìâ Testing set: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "print(f\"üéØ Train churn rate: {y_train.mean():.2%}\")\n",
    "print(f\"üéØ Test churn rate: {y_test.mean():.2%}\")\n",
    "\n",
    "# Feature Scaling using StandardScaler\n",
    "# Neural networks perform better with normalized/standardized features\n",
    "print(\"\\n‚öñÔ∏è Feature Scaling:\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit and transform training data\n",
    "X_test = scaler.transform(X_test)        # Only transform test data (no fitting)\n",
    "\n",
    "print(\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(f\"üìä Scaled training data shape: {X_train.shape}\")\n",
    "print(f\"üìä Scaled testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Scaled Training Data (X_train) - First 5 samples:\n",
      "Features are now standardized (mean‚âà0, std‚âà1)\n",
      "[[ 1.058568    0.90750738  1.71508648  0.68472287 -1.22605881 -0.91025649\n",
      "   0.64104192 -1.030206    1.04208392  1.00175153 -0.57831252 -0.57773517]\n",
      " [ 0.91362605  0.90750738 -0.65993547 -0.6962018   0.41328769 -0.91025649\n",
      "   0.64104192 -1.030206   -0.62355635 -0.99825153  1.72916886 -0.57773517]\n",
      " [ 1.07927399 -1.10191942 -0.18493108 -1.73189531  0.60168748  0.80883036\n",
      "   0.64104192  0.97067965  0.30812779 -0.99825153  1.72916886 -0.57773517]\n",
      " [-0.92920731  0.90750738 -0.18493108 -0.00573947 -1.22605881  0.80883036\n",
      "   0.64104192 -1.030206   -0.29019914  1.00175153 -0.57831252 -0.57773517]\n",
      " [ 0.42703522  0.90750738  0.95507945  0.3394917   0.54831832  0.80883036\n",
      "  -1.55996038  0.97067965  0.13504224 -0.99825153  1.72916886 -0.57773517]]\n",
      "\n",
      "üìà Scaling Verification:\n",
      "Mean of scaled features: -0.000000\n",
      "Standard deviation of scaled features: 1.000000\n",
      "üí° Values close to 0 and 1 respectively indicate proper scaling\n"
     ]
    }
   ],
   "source": [
    "# Preview the scaled training data\n",
    "print(\"üìä Scaled Training Data (X_train) - First 5 samples:\")\n",
    "print(\"Features are now standardized (mean‚âà0, std‚âà1)\")\n",
    "print(X_train[:5])\n",
    "\n",
    "print(f\"\\nüìà Scaling Verification:\")\n",
    "print(f\"Mean of scaled features: {X_train.mean():.6f}\")\n",
    "print(f\"Standard deviation of scaled features: {X_train.std():.6f}\")\n",
    "print(\"üí° Values close to 0 and 1 respectively indicate proper scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ StandardScaler saved successfully to '../PickelFiles/scaler.pkl'!\n",
      "‚ö†Ô∏è  Important: Use the same scaler for new predictions to maintain consistency\n",
      "\n",
      "‚ö†Ô∏è  Important: Use the same scaler for new predictions to maintain consistency\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted scaler for future use in predictions\n",
    "# This is crucial for maintaining consistency in feature scaling\n",
    "try:\n",
    "    with open('../PickelFiles/scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    \n",
    "    print(\"üíæ StandardScaler saved successfully to '../PickelFiles/scaler.pkl'!\")\n",
    "    print(\"‚ö†Ô∏è  Important: Use the same scaler for new predictions to maintain consistency\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving scaler: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Preparation Summary:\n",
      "==================================================\n",
      "‚úÖ Original dataset loaded from '../Data/Churn_Modelling.csv'\n",
      "‚úÖ Categorical variables encoded (Gender: Label, Geography: One-Hot)\n",
      "‚úÖ Features scaled using StandardScaler\n",
      "‚úÖ Data split into train/test sets (80/20)\n",
      "‚úÖ All preprocessors saved to '../PickelFiles/'\n",
      "\n",
      "üìä Final Data Shapes:\n",
      "üî¢ Number of input features: 12\n",
      "üìà Training samples: 8000\n",
      "üìâ Testing samples: 2000\n",
      "\n",
      "üöÄ Ready for Neural Network Model Development!\n"
     ]
    }
   ],
   "source": [
    "# Final verification before model training\n",
    "print(\"‚úÖ Data Preparation Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚úÖ Original dataset loaded from '../Data/Churn_Modelling.csv'\")\n",
    "print(f\"‚úÖ Categorical variables encoded (Gender: Label, Geography: One-Hot)\")\n",
    "print(f\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(f\"‚úÖ Data split into train/test sets (80/20)\")\n",
    "print(f\"‚úÖ All preprocessors saved to '../PickelFiles/'\")\n",
    "\n",
    "print(f\"\\nüìä Final Data Shapes:\")\n",
    "print(f\"üî¢ Number of input features: {X_train.shape[1]}\")\n",
    "print(f\"üìà Training samples: {X_train.shape[0]}\")\n",
    "print(f\"üìâ Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for Neural Network Model Development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Artificial Neural Network (ANN) Implementation\n",
    "\n",
    "## Model Architecture Design\n",
    "We'll build a deep neural network for binary classification with the following characteristics:\n",
    "\n",
    "### Architecture Overview\n",
    "- **Input Layer**: Accepts all preprocessed features\n",
    "- **Hidden Layer 1**: 64 neurons with ReLU activation\n",
    "- **Hidden Layer 2**: 32 neurons with ReLU activation  \n",
    "- **Output Layer**: 1 neuron with Sigmoid activation (probability output)\n",
    "\n",
    "### Key Design Decisions\n",
    "- **ReLU Activation**: Prevents vanishing gradient problem\n",
    "- **Sigmoid Output**: Outputs probability between 0 and 1\n",
    "- **Decreasing Layer Size**: Creates hierarchical feature learning\n",
    "- **Binary Classification**: Perfect for churn prediction (Yes/No)\n",
    "\n",
    "### Training Strategy\n",
    "- **Optimizer**: Adam (adaptive learning rate)\n",
    "- **Loss Function**: Binary Crossentropy\n",
    "- **Metrics**: Accuracy tracking\n",
    "- **Callbacks**: Early Stopping, TensorBoard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "üß† Starting Deep Learning Model Development...\n",
      "üîß TensorFlow version: 2.15.0\n",
      "üñ•Ô∏è GPU Available: False\n",
      "üíæ Physical devices: ['/physical_device:CPU:0']\n",
      "‚úÖ All TensorFlow components imported successfully!\n",
      "üß† Starting Deep Learning Model Development...\n",
      "üîß TensorFlow version: 2.15.0\n",
      "üñ•Ô∏è GPU Available: False\n",
      "üíæ Physical devices: ['/physical_device:CPU:0']\n",
      "‚úÖ All TensorFlow components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 10. DEEP LEARNING MODEL IMPLEMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "# Import TensorFlow and Keras components for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"üß† Starting Deep Learning Model Development...\")\n",
    "print(f\"üîß TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üñ•Ô∏è GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(f\"üíæ Physical devices: {[device.name for device in tf.config.list_physical_devices()]}\")\n",
    "print(\"‚úÖ All TensorFlow components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Number of input features: 12\n",
      "üìê Input shape for neural network: (12,)\n",
      "üí° This will be the input layer size for our neural network\n",
      "\n",
      "üìä Training Data Summary:\n",
      "üìà Training samples: 8,000\n",
      "üìâ Testing samples: 2,000\n",
      "üéØ Features per sample: 12\n",
      "üìä Total training parameters needed: ~768 (first layer)\n"
     ]
    }
   ],
   "source": [
    "# Check the number of input features for the model architecture\n",
    "input_features = X_train.shape[1]\n",
    "print(f\"üî¢ Number of input features: {input_features}\")\n",
    "print(f\"üìê Input shape for neural network: {(input_features,)}\")\n",
    "print(\"üí° This will be the input layer size for our neural network\")\n",
    "\n",
    "print(f\"\\nüìä Training Data Summary:\")\n",
    "print(f\"üìà Training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"üìâ Testing samples: {X_test.shape[0]:,}\")\n",
    "print(f\"üéØ Features per sample: {input_features}\")\n",
    "print(f\"üìä Total training parameters needed: ~{input_features * 64:,} (first layer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "üèóÔ∏è Model Architecture Created!\n",
      "üìã Architecture: Input ‚Üí Dense(64) ‚Üí BatchNorm ‚Üí Dropout(0.3) ‚Üí Dense(32) ‚Üí BatchNorm ‚Üí Dropout(0.2) ‚Üí Dense(1)\n",
      "üîß Activation Functions: ReLU (hidden layers), Sigmoid (output layer)\n",
      "‚ö° Regularization: Batch Normalization + Dropout\n",
      "üèóÔ∏è Model Architecture Created!\n",
      "üìã Architecture: Input ‚Üí Dense(64) ‚Üí BatchNorm ‚Üí Dropout(0.3) ‚Üí Dense(32) ‚Üí BatchNorm ‚Üí Dropout(0.2) ‚Üí Dense(1)\n",
      "üîß Activation Functions: ReLU (hidden layers), Sigmoid (output layer)\n",
      "‚ö° Regularization: Batch Normalization + Dropout\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 11. MODEL ARCHITECTURE DESIGN\n",
    "# =============================================================================\n",
    "\n",
    "# Build an optimized ANN model for churn prediction\n",
    "# Architecture: Input ‚Üí Hidden Layer 1 ‚Üí Hidden Layer 2 ‚Üí Output\n",
    "\n",
    "model = Sequential([\n",
    "    # Input Layer + First Hidden Layer\n",
    "    # 64 neurons with ReLU activation for non-linearity\n",
    "    Dense(64, activation='relu', input_shape=(input_features,), name='hidden_layer_1'),\n",
    "    BatchNormalization(),  # Normalize inputs to each layer\n",
    "    Dropout(0.3),          # Prevent overfitting by randomly setting 30% neurons to 0\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    # 32 neurons (decreasing size for hierarchical feature learning)\n",
    "    Dense(32, activation='relu', name='hidden_layer_2'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),          # Lower dropout rate for deeper layer\n",
    "    \n",
    "    # Output Layer\n",
    "    # 1 neuron with sigmoid activation for binary classification (0-1 probability)\n",
    "    Dense(1, activation='sigmoid', name='output_layer')\n",
    "])\n",
    "\n",
    "print(\"üèóÔ∏è Model Architecture Created!\")\n",
    "print(\"üìã Architecture: Input ‚Üí Dense(64) ‚Üí BatchNorm ‚Üí Dropout(0.3) ‚Üí Dense(32) ‚Üí BatchNorm ‚Üí Dropout(0.2) ‚Üí Dense(1)\")\n",
    "print(\"üîß Activation Functions: ReLU (hidden layers), Sigmoid (output layer)\")\n",
    "print(\"‚ö° Regularization: Batch Normalization + Dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Detailed Model Summary:\n",
      "============================================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 64)                832       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 64)                832       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3329 (13.00 KB)\n",
      "Trainable params: 3137 (12.25 KB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3329 (13.00 KB)\n",
      "Trainable params: 3137 (12.25 KB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "üìä Parameter Analysis:\n",
      "üî¢ Total Parameters: 3,329\n",
      "üéØ Trainable Parameters: 3,137\n",
      "üîí Non-trainable Parameters: 192\n",
      "üí° More parameters = higher capacity but risk of overfitting\n",
      "\n",
      "üß† Model Complexity:\n",
      "üìè Model depth: 7 layers\n",
      "üîó Connections: 3,137 weights and biases to learn\n",
      "üíæ Memory footprint: ~13.0 KB (32-bit floats)\n",
      "\n",
      "üìä Parameter Analysis:\n",
      "üî¢ Total Parameters: 3,329\n",
      "üéØ Trainable Parameters: 3,137\n",
      "üîí Non-trainable Parameters: 192\n",
      "üí° More parameters = higher capacity but risk of overfitting\n",
      "\n",
      "üß† Model Complexity:\n",
      "üìè Model depth: 7 layers\n",
      "üîó Connections: 3,137 weights and biases to learn\n",
      "üíæ Memory footprint: ~13.0 KB (32-bit floats)\n"
     ]
    }
   ],
   "source": [
    "# Display detailed model architecture\n",
    "print(\"üìã Detailed Model Summary:\")\n",
    "print(\"=\" * 60)\n",
    "model.summary()\n",
    "\n",
    "# Calculate and display total parameters\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_params = sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print(f\"\\nüìä Parameter Analysis:\")\n",
    "print(f\"üî¢ Total Parameters: {total_params:,}\")\n",
    "print(f\"üéØ Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"üîí Non-trainable Parameters: {non_trainable_params:,}\")\n",
    "print(\"üí° More parameters = higher capacity but risk of overfitting\")\n",
    "\n",
    "# Estimate model complexity\n",
    "print(f\"\\nüß† Model Complexity:\")\n",
    "print(f\"üìè Model depth: {len(model.layers)} layers\")\n",
    "print(f\"üîó Connections: {trainable_params:,} weights and biases to learn\")\n",
    "print(f\"üíæ Memory footprint: ~{(total_params * 4) / 1024:.1f} KB (32-bit floats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuring Model Training Parameters...\n",
      "üìà Learning rate: 0.001\n",
      "üîß Optimizer: adam\n",
      "üìâ Loss function: binary_crossentropy\n",
      "üìä Metrics: accuracy\n",
      "üí° Using string names for better TensorFlow version compatibility\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 12. MODEL COMPILATION CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Configure optimizer and loss function for training\n",
    "# Using string names for better TensorFlow version compatibility\n",
    "\n",
    "print(\"‚öôÔ∏è Configuring Model Training Parameters...\")\n",
    "\n",
    "# Learning rate selection\n",
    "learning_rate = 0.001  # Default Adam learning rate, good starting point\n",
    "print(f\"üìà Learning rate: {learning_rate}\")\n",
    "\n",
    "# Create optimizer and loss function\n",
    "# Using string names instead of objects for better compatibility\n",
    "optimizer_name = 'adam'\n",
    "loss_function = 'binary_crossentropy'\n",
    "\n",
    "print(f\"üîß Optimizer: {optimizer_name}\")\n",
    "print(f\"üìâ Loss function: {loss_function}\")\n",
    "print(f\"üìä Metrics: accuracy\")\n",
    "print(\"üí° Using string names for better TensorFlow version compatibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "‚úÖ Model Compiled Successfully!\n",
      "üîß Optimizer: adam\n",
      "üìâ Loss Function: binary_crossentropy\n",
      "üìä Metrics: accuracy\n",
      "üöÄ Model is ready for training!\n",
      "‚úÖ Model Compiled Successfully!\n",
      "üîß Optimizer: adam\n",
      "üìâ Loss Function: binary_crossentropy\n",
      "üìä Metrics: accuracy\n",
      "üöÄ Model is ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with optimized hyperparameters\n",
    "model.compile(\n",
    "    optimizer=optimizer_name,        # Use string name for compatibility\n",
    "    loss=loss_function,              # Binary crossentropy for binary classification\n",
    "    metrics=['accuracy']             # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model Compiled Successfully!\")\n",
    "print(f\"üîß Optimizer: {optimizer_name}\")\n",
    "print(f\"üìâ Loss Function: {loss_function}\")\n",
    "print(f\"üìä Metrics: accuracy\")\n",
    "print(\"üöÄ Model is ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TensorBoard Configuration:\n",
      "üìÅ Log directory: ../logs/fit/20250801-162303\n",
      "üìà Logging: Loss, Accuracy, Weight Histograms, Model Graph\n",
      "üí° Use 'tensorboard --logdir ../logs/fit' to view training progress\n",
      "‚úÖ TensorBoard callback configured!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. SETUP TRAINING CALLBACKS\n",
    "# =============================================================================\n",
    "\n",
    "# Create timestamp for unique TensorBoard log directory\n",
    "log_dir = \"../logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Ensure logs directory exists\n",
    "os.makedirs(\"../logs/fit\", exist_ok=True)\n",
    "\n",
    "# Setup TensorBoard callback for training visualization\n",
    "tensorflow_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,           # Log weight histograms every epoch\n",
    "    write_graph=True,           # Log the model graph\n",
    "    write_images=True,          # Log model weights as images\n",
    "    profile_batch=0             # Disable profiling for performance\n",
    ")\n",
    "\n",
    "print(\"üìä TensorBoard Configuration:\")\n",
    "print(f\"üìÅ Log directory: {log_dir}\")\n",
    "print(\"üìà Logging: Loss, Accuracy, Weight Histograms, Model Graph\")\n",
    "print(\"üí° Use 'tensorboard --logdir ../logs/fit' to view training progress\")\n",
    "print(\"‚úÖ TensorBoard callback configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training callbacks configured:\n",
      "üõë Early Stopping: Prevents overfitting (patience=10)\n",
      "üìâ Learning Rate Reduction: Improves convergence (patience=5)\n",
      "üìä TensorBoard: Logs training metrics and visualizations\n",
      "üéØ All callbacks ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Setup Early Stopping to prevent overfitting\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',              # Monitor validation loss\n",
    "    patience=10,                     # Wait 10 epochs before stopping\n",
    "    restore_best_weights=True,       # Restore best weights when stopping\n",
    "    verbose=1                        # Print message when stopping\n",
    ")\n",
    "\n",
    "# Add Learning Rate Reduction for better convergence\n",
    "lr_reducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss',              # Monitor validation loss\n",
    "    factor=0.5,                      # Reduce LR by half\n",
    "    patience=5,                      # Wait 5 epochs before reducing\n",
    "    min_lr=0.0001,                   # Minimum learning rate\n",
    "    verbose=1                        # Print message when reducing\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training callbacks configured:\")\n",
    "print(\"üõë Early Stopping: Prevents overfitting (patience=10)\")\n",
    "print(\"üìâ Learning Rate Reduction: Improves convergence (patience=5)\")\n",
    "print(\"üìä TensorBoard: Logs training metrics and visualizations\")\n",
    "print(\"üéØ All callbacks ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Model Training...\n",
      "‚è±Ô∏è This may take a few minutes depending on your hardware.\n",
      "============================================================\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 4s 8ms/step - loss: 0.6077 - accuracy: 0.6925 - val_loss: 0.4163 - val_accuracy: 0.8280 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 4s 8ms/step - loss: 0.6077 - accuracy: 0.6925 - val_loss: 0.4163 - val_accuracy: 0.8280 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4401 - accuracy: 0.8089 - val_loss: 0.3667 - val_accuracy: 0.8505 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4401 - accuracy: 0.8089 - val_loss: 0.3667 - val_accuracy: 0.8505 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8198 - val_loss: 0.3558 - val_accuracy: 0.8540 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8198 - val_loss: 0.3558 - val_accuracy: 0.8540 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8274 - val_loss: 0.3525 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8274 - val_loss: 0.3525 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.8331 - val_loss: 0.3481 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.8331 - val_loss: 0.3481 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3879 - accuracy: 0.8331 - val_loss: 0.3494 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3879 - accuracy: 0.8331 - val_loss: 0.3494 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8434 - val_loss: 0.3430 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8434 - val_loss: 0.3430 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3687 - accuracy: 0.8421 - val_loss: 0.3429 - val_accuracy: 0.8605 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3687 - accuracy: 0.8421 - val_loss: 0.3429 - val_accuracy: 0.8605 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3666 - accuracy: 0.8476 - val_loss: 0.3408 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3666 - accuracy: 0.8476 - val_loss: 0.3408 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8468 - val_loss: 0.3406 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8468 - val_loss: 0.3406 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3657 - accuracy: 0.8472 - val_loss: 0.3362 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3657 - accuracy: 0.8472 - val_loss: 0.3362 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.8476 - val_loss: 0.3382 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.8476 - val_loss: 0.3382 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3662 - accuracy: 0.8478 - val_loss: 0.3358 - val_accuracy: 0.8670 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3662 - accuracy: 0.8478 - val_loss: 0.3358 - val_accuracy: 0.8670 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3625 - accuracy: 0.8460 - val_loss: 0.3355 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3625 - accuracy: 0.8460 - val_loss: 0.3355 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.3358 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.3358 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3594 - accuracy: 0.8493 - val_loss: 0.3377 - val_accuracy: 0.8635 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3594 - accuracy: 0.8493 - val_loss: 0.3377 - val_accuracy: 0.8635 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3592 - accuracy: 0.8482 - val_loss: 0.3340 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3592 - accuracy: 0.8482 - val_loss: 0.3340 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3530 - accuracy: 0.8566 - val_loss: 0.3361 - val_accuracy: 0.8635 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3530 - accuracy: 0.8566 - val_loss: 0.3361 - val_accuracy: 0.8635 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3573 - accuracy: 0.8533 - val_loss: 0.3354 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3573 - accuracy: 0.8533 - val_loss: 0.3354 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3526 - accuracy: 0.8550 - val_loss: 0.3342 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3526 - accuracy: 0.8550 - val_loss: 0.3342 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3518 - accuracy: 0.8543 - val_loss: 0.3346 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3518 - accuracy: 0.8543 - val_loss: 0.3346 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "237/250 [===========================>..] - ETA: 0s - loss: 0.3488 - accuracy: 0.8560\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3492 - accuracy: 0.8559 - val_loss: 0.3348 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "  1/250 [..............................] - ETA: 0s - loss: 0.4198 - accuracy: 0.7500\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3492 - accuracy: 0.8559 - val_loss: 0.3348 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.8579 - val_loss: 0.3328 - val_accuracy: 0.8670 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.8579 - val_loss: 0.3328 - val_accuracy: 0.8670 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3509 - accuracy: 0.8549 - val_loss: 0.3329 - val_accuracy: 0.8695 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3509 - accuracy: 0.8549 - val_loss: 0.3329 - val_accuracy: 0.8695 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8566 - val_loss: 0.3348 - val_accuracy: 0.8645 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8566 - val_loss: 0.3348 - val_accuracy: 0.8645 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8562 - val_loss: 0.3343 - val_accuracy: 0.8655 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8562 - val_loss: 0.3343 - val_accuracy: 0.8655 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8570 - val_loss: 0.3340 - val_accuracy: 0.8690 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8570 - val_loss: 0.3340 - val_accuracy: 0.8690 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3441 - accuracy: 0.8564 - val_loss: 0.3326 - val_accuracy: 0.8655 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3441 - accuracy: 0.8564 - val_loss: 0.3326 - val_accuracy: 0.8655 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8600 - val_loss: 0.3329 - val_accuracy: 0.8680 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8600 - val_loss: 0.3329 - val_accuracy: 0.8680 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8583 - val_loss: 0.3325 - val_accuracy: 0.8675 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8583 - val_loss: 0.3325 - val_accuracy: 0.8675 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.8586 - val_loss: 0.3327 - val_accuracy: 0.8660 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.8586 - val_loss: 0.3327 - val_accuracy: 0.8660 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8595 - val_loss: 0.3338 - val_accuracy: 0.8650 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8595 - val_loss: 0.3338 - val_accuracy: 0.8650 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3415 - accuracy: 0.8579 - val_loss: 0.3362 - val_accuracy: 0.8685 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3415 - accuracy: 0.8579 - val_loss: 0.3362 - val_accuracy: 0.8685 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8568 - val_loss: 0.3346 - val_accuracy: 0.8700 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8568 - val_loss: 0.3346 - val_accuracy: 0.8700 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8615\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8615 - val_loss: 0.3335 - val_accuracy: 0.8685 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "  1/250 [..............................] - ETA: 0s - loss: 0.1847 - accuracy: 0.9688\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8615 - val_loss: 0.3335 - val_accuracy: 0.8685 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8560 - val_loss: 0.3329 - val_accuracy: 0.8685 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8560 - val_loss: 0.3329 - val_accuracy: 0.8685 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8580 - val_loss: 0.3326 - val_accuracy: 0.8705 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8580 - val_loss: 0.3326 - val_accuracy: 0.8705 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3408 - accuracy: 0.8590 - val_loss: 0.3329 - val_accuracy: 0.8690 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3408 - accuracy: 0.8590 - val_loss: 0.3329 - val_accuracy: 0.8690 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8561 - val_loss: 0.3336 - val_accuracy: 0.8680 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8561 - val_loss: 0.3336 - val_accuracy: 0.8680 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 0.3421 - accuracy: 0.8583Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3455 - accuracy: 0.8571 - val_loss: 0.3328 - val_accuracy: 0.8695 - lr: 2.5000e-04\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3455 - accuracy: 0.8571 - val_loss: 0.3328 - val_accuracy: 0.8695 - lr: 2.5000e-04\n",
      "Epoch 40: early stopping\n",
      "\n",
      "‚úÖ Model Training Completed!\n",
      "üìä Total epochs trained: 40\n",
      "üìà Check TensorBoard for detailed training metrics visualization\n",
      "üíæ Training history saved in 'history' variable\n",
      "\n",
      "üéØ Final Training Metrics:\n",
      "üìâ Training Loss: 0.3455\n",
      "üìà Validation Loss: 0.3328\n",
      "üéØ Training Accuracy: 0.8571 (85.71%)\n",
      "üéØ Validation Accuracy: 0.8695 (86.95%)\n",
      "Epoch 40: early stopping\n",
      "\n",
      "‚úÖ Model Training Completed!\n",
      "üìä Total epochs trained: 40\n",
      "üìà Check TensorBoard for detailed training metrics visualization\n",
      "üíæ Training history saved in 'history' variable\n",
      "\n",
      "üéØ Final Training Metrics:\n",
      "üìâ Training Loss: 0.3455\n",
      "üìà Validation Loss: 0.3328\n",
      "üéØ Training Accuracy: 0.8571 (85.71%)\n",
      "üéØ Validation Accuracy: 0.8695 (86.95%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 14. MODEL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üöÄ Starting Model Training...\")\n",
    "print(\"‚è±Ô∏è This may take a few minutes depending on your hardware.\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train the model with optimized parameters\n",
    "history = model.fit(\n",
    "    X_train, y_train,                           # Training data\n",
    "    validation_data=(X_test, y_test),           # Validation data\n",
    "    epochs=100,                                 # Maximum epochs\n",
    "    batch_size=32,                             # Batch size for training\n",
    "    callbacks=[                                # Training callbacks\n",
    "        tensorflow_callback,                   # TensorBoard logging\n",
    "        early_stopping_callback,               # Early stopping\n",
    "        lr_reducer                             # Learning rate reduction\n",
    "    ],\n",
    "    verbose=1                                  # Show training progress\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model Training Completed!\")\n",
    "print(f\"üìä Total epochs trained: {len(history.history['loss'])}\")\n",
    "print(\"üìà Check TensorBoard for detailed training metrics visualization\")\n",
    "print(f\"üíæ Training history saved in 'history' variable\")\n",
    "\n",
    "# Display final training metrics\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"\\nüéØ Final Training Metrics:\")\n",
    "print(f\"üìâ Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"üìà Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"üéØ Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"üéØ Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving Model in Multiple Formats...\n",
      "‚úÖ Model saved in Keras format: ../PickelFiles/model.keras\n",
      "‚úÖ Model saved in H5 format: ../PickelFiles/model.h5\n",
      "\n",
      "üí° Both formats available:\n",
      "  ‚Ä¢ model.keras - Recommended for new deployments\n",
      "  ‚Ä¢ model.h5 - For backward compatibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suraj Khodade\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Model Performance on Test Set:\n",
      "=============================================\n",
      "üî• Test Loss:      0.3325\n",
      "üéØ Test Accuracy:  0.8675 (86.75%)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      "üìà Detailed Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1593\n",
      "           1       0.77      0.50      0.60       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.73      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "\n",
      "üéâ Model Training and Saving Complete!\n",
      "üìÅ All files saved to '../PickelFiles/' directory\n",
      "\n",
      "üìà Detailed Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1593\n",
      "           1       0.77      0.50      0.60       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.73      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "\n",
      "üéâ Model Training and Saving Complete!\n",
      "üìÅ All files saved to '../PickelFiles/' directory\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 15. MODEL SAVING AND EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üíæ Saving Model in Multiple Formats...\")\n",
    "\n",
    "try:\n",
    "    # Save in newer Keras format (recommended)\n",
    "    model_keras_path = '../PickelFiles/model.keras'\n",
    "    model.save(model_keras_path)\n",
    "    print(f\"‚úÖ Model saved in Keras format: {model_keras_path}\")\n",
    "\n",
    "    # Save in H5 format for backward compatibility\n",
    "    model_h5_path = '../PickelFiles/model.h5'\n",
    "    model.save(model_h5_path, save_format='h5')\n",
    "    print(f\"‚úÖ Model saved in H5 format: {model_h5_path}\")\n",
    "\n",
    "    print(\"\\nüí° Both formats available:\")\n",
    "    print(\"  ‚Ä¢ model.keras - Recommended for new deployments\")\n",
    "    print(\"  ‚Ä¢ model.h5 - For backward compatibility\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Quick evaluation on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nüìä Final Model Performance on Test Set:\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üî• Test Loss:      {test_loss:.4f}\")\n",
    "print(f\"üéØ Test Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nüìà Detailed Performance Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nüéâ Model Training and Saving Complete!\")\n",
    "print(f\"üìÅ All files saved to '../PickelFiles/' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TensorBoard extension loaded!\n",
      "üöÄ You can now visualize training metrics, model architecture, and more\n",
      "\n",
      "üìà Available visualizations:\n",
      "  ‚Ä¢ Training/Validation Loss and Accuracy curves\n",
      "  ‚Ä¢ Model architecture graph\n",
      "  ‚Ä¢ Weight and bias histograms\n",
      "  ‚Ä¢ Learning rate changes\n",
      "  ‚Ä¢ Gradient distributions\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 16. TENSORBOARD VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load TensorBoard extension for Jupyter notebooks\n",
    "%load_ext tensorboard\n",
    "\n",
    "print(\"üìä TensorBoard extension loaded!\")\n",
    "print(\"üöÄ You can now visualize training metrics, model architecture, and more\")\n",
    "print(\"\\nüìà Available visualizations:\")\n",
    "print(\"  ‚Ä¢ Training/Validation Loss and Accuracy curves\")\n",
    "print(\"  ‚Ä¢ Model architecture graph\")\n",
    "print(\"  ‚Ä¢ Weight and bias histograms\")\n",
    "print(\"  ‚Ä¢ Learning rate changes\")\n",
    "print(\"  ‚Ä¢ Gradient distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching TensorBoard...\n",
      "üìà Interactive visualization of model training\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3292026493e2e7d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3292026493e2e7d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° TensorBoard Tips:\n",
      "‚Ä¢ Scalars: View loss and accuracy curves\n",
      "‚Ä¢ Graphs: Explore model architecture\n",
      "‚Ä¢ Histograms: Analyze weight distributions\n",
      "‚Ä¢ Images: Visualize weight matrices\n",
      "‚Ä¢ Use the timeline slider to see training progress\n"
     ]
    }
   ],
   "source": [
    "# Launch TensorBoard to visualize training metrics\n",
    "print(\"üöÄ Launching TensorBoard...\")\n",
    "print(\"üìà Interactive visualization of model training\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "%tensorboard --logdir ../logs/fit\n",
    "\n",
    "print(\"\\nüí° TensorBoard Tips:\")\n",
    "print(\"‚Ä¢ Scalars: View loss and accuracy curves\")\n",
    "print(\"‚Ä¢ Graphs: Explore model architecture\")\n",
    "print(\"‚Ä¢ Histograms: Analyze weight distributions\")\n",
    "print(\"‚Ä¢ Images: Visualize weight matrices\")\n",
    "print(\"‚Ä¢ Use the timeline slider to see training progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ CUSTOMER CHURN PREDICTION MODEL - EXPERIMENT COMPLETED!\n",
      "============================================================\n",
      "‚úÖ Data preprocessing completed\n",
      "‚úÖ Neural network model trained and saved\n",
      "‚úÖ Encoders and scaler saved for future predictions\n",
      "‚úÖ TensorBoard logs generated for analysis\n",
      "\n",
      "üìÅ Generated Files in '../PickelFiles/':\n",
      "  ‚Ä¢ model.keras - Trained neural network (recommended)\n",
      "  ‚Ä¢ model.h5 - Trained neural network (compatibility)\n",
      "  ‚Ä¢ label_encoder_gender.pkl - Gender encoder\n",
      "  ‚Ä¢ onehot_encoder_geo.pkl - Geography encoder\n",
      "  ‚Ä¢ scaler.pkl - Feature scaler\n",
      "\n",
      "üìä Generated Logs in '../logs/fit/':\n",
      "  ‚Ä¢ TensorBoard training logs\n",
      "  ‚Ä¢ Model architecture graphs\n",
      "  ‚Ä¢ Training metrics history\n",
      "\n",
      "üîÑ Next Steps:\n",
      "  1. Use '../Notebook/prediction.ipynb' for individual predictions\n",
      "  2. Use '../app.py' to run the Streamlit web application\n",
      "  3. Analyze TensorBoard visualizations for model insights\n",
      "  4. Consider hyperparameter tuning for improved performance\n",
      "  5. Deploy to Streamlit Cloud for public access\n",
      "\n",
      "üöÄ Ready for Production Deployment!\n",
      "üí° All preprocessors and models are saved for consistent predictions\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 17. EXPERIMENT CONCLUSION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéâ CUSTOMER CHURN PREDICTION MODEL - EXPERIMENT COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Data preprocessing completed\")\n",
    "print(\"‚úÖ Neural network model trained and saved\")\n",
    "print(\"‚úÖ Encoders and scaler saved for future predictions\")\n",
    "print(\"‚úÖ TensorBoard logs generated for analysis\")\n",
    "\n",
    "print(\"\\nüìÅ Generated Files in '../PickelFiles/':\")\n",
    "print(\"  ‚Ä¢ model.keras - Trained neural network (recommended)\")\n",
    "print(\"  ‚Ä¢ model.h5 - Trained neural network (compatibility)\")\n",
    "print(\"  ‚Ä¢ label_encoder_gender.pkl - Gender encoder\")\n",
    "print(\"  ‚Ä¢ onehot_encoder_geo.pkl - Geography encoder\") \n",
    "print(\"  ‚Ä¢ scaler.pkl - Feature scaler\")\n",
    "\n",
    "print(\"\\nüìä Generated Logs in '../logs/fit/':\")\n",
    "print(\"  ‚Ä¢ TensorBoard training logs\")\n",
    "print(\"  ‚Ä¢ Model architecture graphs\")\n",
    "print(\"  ‚Ä¢ Training metrics history\")\n",
    "\n",
    "print(\"\\nüîÑ Next Steps:\")\n",
    "print(\"  1. Use '../Notebook/prediction.ipynb' for individual predictions\")\n",
    "print(\"  2. Use '../app.py' to run the Streamlit web application\")\n",
    "print(\"  3. Analyze TensorBoard visualizations for model insights\")\n",
    "print(\"  4. Consider hyperparameter tuning for improved performance\")\n",
    "print(\"  5. Deploy to Streamlit Cloud for public access\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for Production Deployment!\")\n",
    "print(\"üí° All preprocessors and models are saved for consistent predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
